# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_hv6eatjbXd3CsQaXvWPklHwwhHLKMOh
"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
import re
import string

nltk.download('vader_lexicon')
nltk.download('punkt')
nltk.download('wordnet')

stop_words = stopwords.words('english')
lzr = WordNetLemmatizer()

def text_processing(text):
    text = text.lower()
    text = re.sub(r'\n',' ', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), "", text)
    text = re.sub("^a-zA-Z0-9$,.", "", text)
    text = re.sub(r'\s+', ' ', text, flags=re.I)
    text = re.sub(r'\W', ' ', text)
    text = ' '.join([word for word in word_tokenize(text) if word not in stop_words])
    text = ' '.join([lzr.lemmatize(word) for word in word_tokenize(text)])
    return text

def preprocess_data(data):
    data_copy = data.copy()
    data_copy.text = data_copy.text.apply(lambda text: text_processing(text))

    le = LabelEncoder()
    data_copy['Sentiment'] = le.fit_transform(data_copy['Sentiment'])

    processed_data = {
        'Sentence': data_copy.text,
        'Sentiment': data_copy['Sentiment']
    }

    processed_data = pd.DataFrame(processed_data)
    return processed_data